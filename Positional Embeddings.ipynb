{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to override a python impl for DispatchKey.Meta on operator aten::broadcast_tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset,DataLoader\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/torch/__init__.py:2611\u001b[0m\n\u001b[1;32m   2607\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m vmap \u001b[38;5;28;01mas\u001b[39;00m vmap\n\u001b[1;32m   2610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m-> 2611\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations\n\u001b[1;32m   2613\u001b[0m \u001b[38;5;66;03m# Enable CUDA Sanitizer\u001b[39;00m\n\u001b[1;32m   2614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCH_CUDA_SANITIZER\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/torch/_meta_registrations.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims_common\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SymBool, SymFloat, Tensor\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     _add_op_to_registry,\n\u001b[1;32m     14\u001b[0m     _convert_out_params,\n\u001b[1;32m     15\u001b[0m     global_decomposition_table,\n\u001b[1;32m     16\u001b[0m     meta_table,\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpOverload\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_prims\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _prim_elementwise_meta, ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/torch/_decomp/__init__.py:277\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# populate the table\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decomp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecompositions\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_refs\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcore_aten_decompositions\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustomDecompTable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexported_program\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m default_decompositions\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/torch/_refs/__init__.py:2729\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbroadcast_shapes\u001b[39m(\u001b[38;5;241m*\u001b[39mshapes) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ShapeType:\n\u001b[1;32m   2724\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mSize(_broadcast_shapes(\u001b[38;5;241m*\u001b[39mshapes))\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;129m@aten\u001b[39m\u001b[38;5;241m.\u001b[39mbroadcast_tensors\u001b[38;5;241m.\u001b[39mdefault\u001b[38;5;241m.\u001b[39mpy_impl(DispatchKey\u001b[38;5;241m.\u001b[39mCompositeImplicitAutograd)\n\u001b[1;32m   2728\u001b[0m \u001b[38;5;129m@aten\u001b[39m\u001b[38;5;241m.\u001b[39mbroadcast_tensors\u001b[38;5;241m.\u001b[39mdefault\u001b[38;5;241m.\u001b[39mpy_impl(DispatchKey\u001b[38;5;241m.\u001b[39mMeta)\n\u001b[0;32m-> 2729\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbroadcast_tensors\u001b[39m(\u001b[38;5;241m*\u001b[39mtensors) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[TensorLikeType]:\n\u001b[1;32m   2730\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors[\u001b[38;5;241m0\u001b[39m], Tensor):\n\u001b[1;32m   2731\u001b[0m         tensors \u001b[38;5;241m=\u001b[39m tensors[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/site-packages/torch/_ops.py:141\u001b[0m, in \u001b[0;36mOperatorBase.py_impl.<locals>.inner\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m k \u001b[38;5;241m!=\u001b[39m DispatchKey\u001b[38;5;241m.\u001b[39mPython, (\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease register a mode for the DispatchKey.Python key instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m )\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpy_kernels:\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to override a python impl for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpy_kernels[k] \u001b[38;5;241m=\u001b[39m fn\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_cache\u001b[38;5;241m.\u001b[39mclear()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to override a python impl for DispatchKey.Meta on operator aten::broadcast_tensors"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTDatasetV1(Dataset):\n",
    "    def __init_(self,txt,tokenizer,context_window,stride):\n",
    "        self.input_id=[]\n",
    "        self.target_id=[]\n",
    "\n",
    "        #tokenize the txt dataset\n",
    "        token_ids=tokenizer.encode(txt)\n",
    "\n",
    "        #use sliding window to prepare input target tensor pair\n",
    "\n",
    "        for i in range(0,len(token_id)-context_window,stride):\n",
    "            input_chunk=token_ids[i:i+context_window]\n",
    "            target_chunk=token_ids[i+1:i+context_window+1]\n",
    "            self.input_id.append(torch.tensor(input_chunk))\n",
    "            self.target_id.append(toch.tensor(target_chunk))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_id)\n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "        return self.input_id[idx],self.taget_id[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50257\u001b[39m\n\u001b[1;32m      2\u001b[0m output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[0;32m----> 4\u001b[0m token_embedding_layers\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mEmbedding(vocab_size,output_dim)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "vocab_size=50257\n",
    "output_dim=256\n",
    "\n",
    "token_embedding_layers=torch.nn.Embedding(vocab_size,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.8861,  1.4163,  0.4494,  ..., -0.3207, -0.3117, -0.9449],\n",
      "        [-1.1587,  0.6328,  0.3099,  ..., -0.1728,  1.0254, -0.0744],\n",
      "        [ 0.8538,  2.0898,  0.2110,  ...,  0.4716,  0.7317, -0.5667],\n",
      "        ...,\n",
      "        [-1.8563,  0.1431,  1.7111,  ...,  0.6649,  0.4094, -1.5742],\n",
      "        [-1.1120, -0.4674, -0.5436,  ..., -1.7368,  0.0361,  1.2090],\n",
      "        [-1.5218, -0.2898,  0.6867,  ..., -1.2512, -0.7780, -0.5678]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(token_embedding_layers.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt,batch_size=4,context_window=256,stride=128,shuffle=True,drop_last=True,num_workers=0):\n",
    "\n",
    "    #initialize tokenizer\n",
    "    tokenizer=tiktoken.get_encoding(txt)\n",
    "\n",
    "    #create dataset\n",
    "    dataset=GPTDatasetV1(txt,tokenizer,context_window,stride)\n",
    "\n",
    "    #create dataloader\n",
    "    dataloader=DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return dataloader\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
