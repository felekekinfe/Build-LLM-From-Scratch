{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break the data into word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4358\n"
     ]
    }
   ],
   "source": [
    "with open('data/astu overview.txt','r') as f:\n",
    "    raw_text=f.read()\n",
    "print(len(raw_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['University', 'Name:', 'Adama', 'Science']\n",
      "598\n",
      "599\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text=raw_text\n",
    "result=re.split(r'([./]|\\s)',text)\n",
    "#remove whitespace\n",
    "result=[i.strip(' ') for i in result if i.strip()]\n",
    "print(result[:4])\n",
    "print(len(result))\n",
    "result.append('<|unk|>')\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346\n",
      "{'(ASTU)': 0, '(AU)': 1, '(BSc,': 2, '(Core': 3, '(ICT)': 4, '(MSc,': 5, '(NCTTE)': 6, '(NTC)': 7, '(Note:': 8, '(Schools': 9, '(Science,': 10, '(e': 11, '(for': 12, '(often': 13, ')': 14, ',': 15, '.': 16, '/': 17, '1993:': 18, '2003:': 19, '2005:': 20, '2011:': 21, '28°E': 22, '39': 23, '53°N,': 24, '8': 25, '<|unk|>': 26, 'Academic': 27, 'Accommodation:': 28, 'Adama': 29, 'Address:': 30, 'Administration,': 31, 'Affairs,': 32, 'Aligned': 33, 'Alternative': 34, 'Applied': 35, 'Approx': 36, 'Architecture,': 37, 'Areas': 38, 'Astu': 39, 'B': 40, 'Biology,': 41, 'Biosciences': 42, 'Biotechnology': 43, 'Board': 44, 'Buildings:': 45, 'Campus': 46, 'Campus:': 47, 'Centers:': 48, 'Central': 49, 'Chemical': 50, 'Chemistry,': 51, 'City:': 52, 'Civil': 53, 'Collaborations:': 54, 'Collaborative': 55, 'College': 56, 'Colleges': 57, 'Communication': 58, 'Computer': 59, 'Computing': 60, 'Construction': 61, 'Contributes': 62, 'Coordinates:': 63, 'Country:': 64, 'Designated': 65, 'Dining': 66, 'Dormitories': 67, 'Draws': 68, 'Education': 69, 'Electrical': 70, 'Energy': 71, 'Engineering': 72, 'Engineering(CSE),': 73, 'Engineering,': 74, 'Engineering,Materials': 75, 'Engineering,electronics': 76, 'Enrollment:': 77, 'Environmental': 78, 'Establishment': 79, 'Ethiopia': 80, \"Ethiopia's\": 81, 'Ethiopian': 82, 'Exact': 83, 'Examples:': 84, 'Facilities:': 85, 'Federal': 86, 'Focus': 87, 'Focus):': 88, 'Focus:': 89, 'For': 90, 'Founded': 91, 'Further': 92, 'Geology,': 93, 'Governance:': 94, 'Governed': 95, 'History:': 96, 'Humanities': 97, 'ICT': 98, 'ICT,': 99, 'Incubation': 100, 'Industrial': 101, 'Industry': 102, 'Information': 103, 'Infrastructure:': 104, 'Institute': 105, 'Institutes):': 106, 'Internships': 107, 'Irrigation': 108, 'Key': 109, 'Laboratories:': 110, 'Lecture': 111, 'Led': 112, 'Library:': 113, 'Linkages': 114, 'Located': 115, 'Location:': 116, 'M': 117, 'Main': 118, 'Management': 119, 'Manufacturing': 120, 'Materials': 121, 'Mathematics)': 122, 'Mathematics,': 123, 'May': 124, 'Mechanical': 125, 'Ministry': 126, 'Mission': 127, 'MoUs': 128, 'Name:': 129, 'Names:ASTU': 130, 'Natural': 131, 'Nazareth': 132, 'Nazret': 133, 'Nazret,': 134, 'Offered:': 135, 'One': 136, 'Oromia': 137, 'Partnerships': 138, 'PhD)': 139, 'Pharmacy': 140, 'Physical': 141, 'Physics,': 142, 'Plays': 143, 'Postgraduate': 144, 'President,': 145, 'Presidents': 146, 'Program': 147, 'Programs': 148, 'Public': 149, 'Recreation:': 150, 'Region:': 151, 'Renewable': 152, 'Research': 153, 'Resources': 154, 'Role:': 155, 'S&T': 156, 'STEM': 157, 'School': 158, 'Science': 159, 'Sciences': 160, 'Significance': 161, 'Social': 162, 'Software': 163, 'Specialized': 164, 'Sports': 165, 'Structure': 166, 'Student': 167, 'Studies': 168, 'Teacher': 169, 'Tech)': 170, 'Tech,': 171, 'Technical': 172, 'Technologies': 173, 'Technology': 174, 'Technology,': 175, 'The': 176, 'To': 177, 'Transfer,': 178, 'Type:': 179, 'Typically': 180, 'Undergraduate': 181, 'University': 182, 'Upgraded': 183, 'Vice': 184, 'Vision': 185, 'Water': 186, 'Website:': 187, 'Workshops:': 188, 'a': 189, 'above': 190, 'access': 191, 'across': 192, 'advancement': 193, 'all': 194, 'also': 195, 'and': 196, 'annually': 197, 'applied': 198, 'are': 199, 'areas': 200, 'as': 201, 'astu': 202, 'be': 203, 'become': 204, 'biology': 205, 'by': 206, 'cafeterias': 207, 'called': 208, 'campus': 209, 'can': 210, 'center': 211, 'centers': 212, 'chemical,': 213, 'classrooms': 214, 'communication': 215, 'community': 216, 'conduct': 217, 'consultancy': 218, 'contribute': 219, 'crucial': 220, 'dedicated': 221, 'departmental': 222, 'departments': 223, 'departments)': 224, 'development': 225, 'digital': 226, 'direct': 227, 'disciplines': 228, 'edu': 229, 'education': 230, 'efforts': 231, 'electrical,': 232, 'energy,': 233, 'engineering': 234, 'engineering,': 235, 'enrolls': 236, 'entrepreneurship': 237, 'et': 238, 'etc': 239, 'evolve': 240, 'excellence': 241, 'externships': 242, 'facilities': 243, 'faculty': 244, 'fields': 245, 'fields,': 246, 'focusing': 247, 'for': 248, 'from': 249, 'g': 250, 'graduates': 251, 'halls,': 252, 'highly': 253, 'host': 254, 'human': 255, 'impact': 256, 'in': 257, 'include:': 258, 'industrial': 259, 'industrialization': 260, 'industries': 261, 'industry': 262, 'innovation': 263, 'institutes': 264, 'institutions': 265, 'international': 266, 'internet': 267, 'key': 268, 'labs': 269, 'labs)': 270, 'labs,': 271, 'largest,': 272, 'leading': 273, 'libraries': 274, 'library': 275, 'like': 276, 'local': 277, 'materials': 278, 'mechanical,': 279, 'multiple': 280, 'names': 281, 'national': 282, 'needs': 283, 'network,': 284, 'of': 285, 'often': 286, 'on': 287, 'or': 288, 'other': 289, 'partnerships': 290, 'physical': 291, 'physics,': 292, 'postgraduate': 293, 'practical': 294, 'priorities': 295, 'problem-solving': 296, 'produce': 297, 'programs': 298, 'projects': 299, 'provide': 300, 'public': 301, 'qualified': 302, 'recreational': 303, 'regions': 304, 'relevant': 305, 'renamed': 306, 'renewable': 307, 'representative': 308, 'research': 309, 'resources': 310, 'role': 311, 'roles)': 312, 'schools': 313, 'science': 314, 'science,': 315, 'service': 316, 'services': 317, 'significantly': 318, 'skilled': 319, 'societal': 320, 'solutions': 321, 'specialized': 322, 'structure': 323, 'student': 324, 'students': 325, 'supplying': 326, 'support': 327, 'supportive': 328, 'technological': 329, 'technology': 330, 'the': 331, 'their': 332, 'thematic': 333, 'thousands': 334, 'to': 335, 'training': 336, 'transfer': 337, 'typical': 338, 'undergraduate': 339, 'universities': 340, 'university': 341, 'upgraded': 342, 'various': 343, 'with': 344, 'ww': 345}\n"
     ]
    }
   ],
   "source": [
    "vocab={token:id for id,token in enumerate(sorted(set(result)))}\n",
    "\n",
    "print(len(vocab))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizerV1:\n",
    "    def __init__(self,vocab):\n",
    "        self.str_to_int=vocab\n",
    "        self.int_to_str={int:token for token,int in vocab.items()}\n",
    "    def encode(self,text):\n",
    "        processed=sorted(set(re.split(r'([./]|\\s)',text)))\n",
    "        processed=[token for token in processed if token.strip()]\n",
    "        processed=[item if item in self.str_to_int\n",
    "                    else '<|unk|>' for item in processed]\n",
    "        id=[self.str_to_int[token] for token in processed]\n",
    "\n",
    "        return id\n",
    "    def decode(self,ids):\n",
    "        text=' '.join([self.int_to_str[i] for i in ids])\n",
    "        #replace space before the specified punctuations\n",
    "        token=re.sub(r'([,.?]|\\s)',r'\\1',text)\n",
    "        return token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|unk|>'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer=TokenizerV1(vocab)\n",
    "text='Adam'\n",
    "tokenizer.encode(text)\n",
    "tokenizer.decode([26])\n",
    "\n",
    "#disadvantage of this tokenizer is that it fails if the word not in vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Byte Pair tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=tiktoken.get_encoding('gpt2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'Encoding' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'Encoding' has no len()"
     ]
    }
   ],
   "source": [
    "print(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21009, 6530, 25, 1215, 1689, 5800, 290, 8987, 2059, 357, 11262, 52, 8, 393, 635, 1444, 8304, 84, 198, 198, 49788, 28531, 25, 11262, 52, 198, 198, 14749, 25, 198, 14941, 25, 1215, 1689, 14, 37235, 1186, 198, 47371, 25, 440, 398, 544, 198, 33921, 25, 31592, 198, 4677, 13907, 13, 22819, 17540, 25, 807, 13, 4310, 7200, 45, 11, 5014, 13, 2078, 7200, 36, 198, 198, 22362, 25380, 7443, 25, 198, 24465, 25, 4062, 276, 355, 12819, 26659, 20671, 5535, 357, 45, 4825, 737, 198, 16088, 25, 3205, 21791, 284, 12819, 26659, 5535, 286, 20671, 32019, 7868, 357, 45, 4177, 9328, 737, 198, 14315, 25, 7735, 17955, 284, 1215, 1689, 2059, 357, 26830, 737, 198, 9804, 25, 8495, 515, 416, 262, 47689, 9475, 286, 7868, 355, 257, 5618, 2059, 286, 8987, 290, 25121, 1215, 1689, 5800, 290, 8987, 2059, 357, 11262, 52, 737, 198, 198, 6030, 25, 198, 15202, 2059, 198, 24099, 2059, 286, 5800, 290, 8987, 198, 198, 37057, 357, 14055, 17061, 2599, 198, 2514, 4439, 4047, 10617, 19087, 287, 3783, 11, 8705, 11, 290, 3037, 13, 198, 2514, 3189, 1917, 12, 82, 10890, 2267, 5981, 284, 2260, 2478, 2476, 13, 198, 2514, 2148, 2055, 2139, 290, 3037, 4351, 13, 198, 2514, 1716, 257, 3641, 286, 25230, 287, 5625, 311, 5, 51, 3707, 290, 2267, 13, 198, 198, 44206, 357, 14055, 17061, 2599, 198, 2514, 307, 257, 3756, 3230, 6403, 286, 3783, 290, 3037, 13, 198, 2514, 5566, 8676, 284, 31592, 338, 7593, 1634, 290, 14614, 27647, 13, 198, 198, 12832, 49113, 32522, 357, 26130, 82, 14, 5216, 1455, 274, 14, 6310, 16845, 2599, 198, 26130, 286, 14044, 357, 28950, 262, 4387, 11, 351, 3294, 13346, 8, 198, 27730, 25, 19663, 14044, 11, 7511, 14044, 290, 29778, 11, 24872, 14044, 11, 5638, 13864, 290, 5686, 4359, 341, 14044, 11, 41657, 5800, 290, 14044, 13, 198, 26130, 286, 27684, 12068, 13473, 198, 27730, 25, 23123, 11, 27867, 11, 39448, 11, 24698, 11, 2269, 1435, 11, 19234, 1590, 13, 198, 26130, 286, 40224, 14044, 290, 38589, 198, 27730, 25, 13851, 5800, 290, 14044, 7, 34, 5188, 828, 10442, 14044, 11, 9509, 20844, 290, 6946, 8705, 13, 198, 26130, 286, 5524, 871, 290, 5483, 13473, 357, 28950, 16443, 9176, 8, 198, 6310, 3678, 286, 8987, 198, 6307, 17680, 10422, 6118, 198, 198, 7, 6425, 25, 1475, 529, 3891, 286, 4266, 14, 10378, 32514, 290, 511, 4645, 460, 18101, 13, 383, 2029, 389, 7226, 290, 8852, 2014, 198, 198, 9218, 26179, 3242, 1068, 25, 198, 9203, 17680, 357, 33, 3351, 11, 347, 13, 17760, 8, 198, 6307, 17680, 357, 44, 3351, 11, 337, 13, 17760, 11, 16394, 8, 198, 34888, 319, 34133, 7032, 357, 26959, 11, 8987, 11, 14044, 11, 39448, 737, 198, 198, 21111, 385, 290, 48939, 25, 198, 13383, 25005, 25, 40764, 287, 1215, 1689, 14, 37235, 1186, 13, 198, 12832, 49113, 49308, 25, 31209, 495, 24350, 11, 32579, 13, 198, 42230, 19854, 25, 6093, 1143, 27887, 329, 2972, 8705, 290, 3783, 29861, 357, 68, 13, 70, 1539, 12278, 11, 12370, 11, 5931, 11, 11887, 11, 17219, 27887, 737, 198, 23044, 21936, 25, 1114, 8472, 3047, 287, 8705, 29861, 13, 198, 23377, 25, 5694, 5888, 290, 5011, 282, 12782, 351, 3518, 290, 4875, 4133, 13, 198, 18379, 33709, 25, 13851, 27887, 11, 7611, 3127, 11, 5230, 1895, 13, 198, 38778, 6366, 8641, 341, 25, 360, 579, 270, 1749, 13, 198, 35, 3191, 48939, 25, 13613, 19945, 2357, 4448, 13, 198, 18153, 290, 34285, 25, 7092, 7032, 11, 18136, 7291, 13, 198, 25104, 22223, 25, 1737, 2583, 16976, 2267, 10399, 393, 6113, 1769, 10759, 319, 3006, 588, 15713, 2568, 11, 5696, 3783, 11, 314, 4177, 11, 3503, 13, 198, 25517, 549, 341, 22223, 25, 1675, 1104, 3710, 290, 12829, 11044, 290, 44436, 13, 198, 198, 25104, 38662, 290, 17061, 25, 198, 2348, 3916, 351, 2260, 2478, 15369, 286, 31592, 13, 198, 4677, 18511, 2267, 351, 1277, 7593, 290, 26877, 2928, 13, 198, 9218, 606, 1512, 3006, 1690, 2291, 25, 198, 26764, 413, 540, 6682, 21852, 198, 44445, 870, 290, 19034, 14044, 198, 41657, 5800, 290, 14044, 198, 19184, 13864, 290, 13272, 14044, 198, 21918, 290, 26117, 8987, 357, 18379, 8, 8136, 198, 36687, 8987, 290, 8549, 198, 23286, 31201, 290, 27684, 347, 4267, 979, 3007, 628, 198, 35848, 563, 7502, 1095, 290, 37322, 602, 25, 198, 16632, 5842, 290, 22867, 351, 1957, 290, 3230, 11798, 13, 198, 15865, 26313, 290, 409, 759, 26313, 329, 2444, 13, 198, 22667, 4820, 876, 2267, 4493, 351, 2831, 13, 198, 44893, 4351, 290, 47827, 2594, 13, 198, 7841, 2741, 5748, 351, 584, 2260, 290, 3230, 11155, 290, 2267, 6712, 13, 198, 198, 38778, 2039, 48108, 25, 198, 49321, 14627, 82, 4138, 286, 2444, 13844, 1973, 22952, 290, 1281, 17680, 4056, 13, 198, 25302, 82, 2444, 422, 477, 7652, 286, 31592, 13, 198, 198, 29168, 590, 25, 198, 29168, 276, 416, 257, 2059, 5926, 13, 198, 42416, 416, 257, 1992, 11, 11079, 35506, 357, 1640, 31421, 10665, 11, 4992, 290, 8987, 20558, 11, 8694, 11, 3503, 15729, 198, 198, 11712, 811, 590, 290, 20934, 25, 198, 3198, 286, 31592, 338, 1994, 1171, 11155, 7256, 284, 3783, 290, 3037, 13, 198, 3646, 592, 257, 8780, 2597, 287, 28099, 14297, 1692, 4133, 329, 31592, 338, 7593, 290, 14614, 2478, 13, 198, 4264, 7657, 284, 2260, 2267, 290, 11044, 4040, 13, 198, 198, 33420, 25, 266, 86, 13, 459, 84, 13, 15532, 13, 316, 198, 31611, 17917, 25, 1215, 1689, 14, 37235, 1186, 11, 31592, 628, 628]\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "text=('ekkk'\n",
    "      'a')\n",
    "ids=tokenizer.encode(raw_text,allowed_special={'<|endoftext|>'})\n",
    "print(ids)\n",
    "token=tokenizer.decode([1])\n",
    "pri nt(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.4605, -1.3943,  0.6850],\n",
      "        [ 1.3110,  2.5758,  1.0280],\n",
      "        [ 1.3793,  0.6920,  0.8898],\n",
      "        ...,\n",
      "        [-1.4195,  0.9191,  0.8921],\n",
      "        [ 0.7521,  1.0173,  0.4868],\n",
      "        [ 0.1558, -0.3793, -0.9032]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#for simplicity use vocab size 6 and embedding size 3\n",
    "\n",
    "vocab_size=len(vocab)\n",
    "output_dim=3\n",
    "\n",
    "embedding_layers=torch.nn.Embedding(vocab_size,output_dim)\n",
    "print(embedding_layers.weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
